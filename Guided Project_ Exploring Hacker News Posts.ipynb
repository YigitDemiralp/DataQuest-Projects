{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3 align=\"center\">Exploring Hackers News Posts</h3>\n",
    "Hacker news is a site started by the startup incubator Y Combinator, where user-submitted stories (known as 'posts') are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id - The unique identifier from Hacker News for the post\n",
    "\n",
    "title - The title of the post\n",
    "\n",
    "url - The URL that the posts links to, if it the post has a URL\n",
    "\n",
    "num_points - The number of points the post acquired, calculated as the total\n",
    "\n",
    "number of upvotes minus the total number of downvotes\n",
    "\n",
    "num_comments - The number of comments that were made on the post\n",
    "\n",
    "author - The username of the person who submitted the post\n",
    "\n",
    "created_at - The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']]\n"
     ]
    }
   ],
   "source": [
    "#we read the file\n",
    "import csv\n",
    "\n",
    "opened = open(\"hacker_news.csv\")\n",
    "hn = list(csv.reader(opened))\n",
    "\n",
    "#We print the first 5 rows to see what our data looks like \n",
    "print(hn[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Headers from a List of Lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "#We assign the first row to \"headers\"\n",
    "\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(hn[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Ask HN and Show HN Posts\n",
    "\n",
    "\n",
    "We are interested in posts that start with \"Ask HN\" or \"Show HN\" so we are going to filter out these posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(other_posts)\n",
    "\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask HN vs. Show HN. \n",
    "We are going to determine if Ask HN or Show HN posts receive more comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04\n"
     ]
    }
   ],
   "source": [
    "#We calculate the ask comments average\n",
    "total_ask_comments = 0\n",
    "\n",
    "for post in ask_posts:\n",
    "    num_comments = post[4]\n",
    "    num_comments = int(num_comments)\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = \"{:.4}\".format(total_ask_comments / len(ask_posts))\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.32\n"
     ]
    }
   ],
   "source": [
    "#We calculate the show comments average\n",
    "total_show_comments = 0\n",
    "\n",
    "for post in show_posts:\n",
    "    total_show_comments += int(post[4])\n",
    "    \n",
    "avg_show_comments = \"{:.4}\".format(total_show_comments / len(show_posts))\n",
    "print(avg_show_comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the findings we see that Ask HN posts receive about 14 comments on average comments while Show HN posts receive around 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "Since Ask HN posts receive more comments we are going to explore Ask HN posts.\n",
    "\n",
    "We are going to:\n",
    "\n",
    "Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    "\n",
    "Calculate the average number of comments ask posts receive by hour created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'19': 1188, '21': 1745, '08': 492, '03': 421, '04': 337, '14': 1416, '22': 479, '11': 641, '01': 683, '16': 1814, '15': 4477, '06': 397, '18': 1439, '09': 251, '10': 793, '05': 464, '13': 1253, '07': 267, '12': 687, '20': 1722, '00': 447, '17': 1146, '23': 543, '02': 1381}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for post in ask_posts:\n",
    "    result_list.append([post[6], int(post[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    time = dt.datetime.strptime(row[0],\"%m/%d/%Y %H:%M\").strftime(\"%H\")\n",
    "    \n",
    "    if time not in counts_by_hour:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += row[1]\n",
    "        \n",
    "print(comments_by_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counts_by_hour: contains the number of ask posts created during each hour of the day\n",
    "comments_by_hour: contains the corresponding number of comments ask posts created at each hour received\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['19', 10.8],\n",
       " ['21', 16.009174311926607],\n",
       " ['08', 10.25],\n",
       " ['03', 7.796296296296297],\n",
       " ['04', 7.170212765957447],\n",
       " ['14', 13.233644859813085],\n",
       " ['22', 6.746478873239437],\n",
       " ['11', 11.051724137931034],\n",
       " ['01', 11.383333333333333],\n",
       " ['16', 16.796296296296298],\n",
       " ['15', 38.5948275862069],\n",
       " ['06', 9.022727272727273],\n",
       " ['18', 13.20183486238532],\n",
       " ['09', 5.5777777777777775],\n",
       " ['10', 13.440677966101696],\n",
       " ['05', 10.08695652173913],\n",
       " ['13', 14.741176470588234],\n",
       " ['07', 7.852941176470588],\n",
       " ['12', 9.41095890410959],\n",
       " ['20', 21.525],\n",
       " ['00', 8.127272727272727],\n",
       " ['17', 11.46],\n",
       " ['23', 7.985294117647059],\n",
       " ['02', 23.810344827586206]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/ counts_by_hour[hour]])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.8, '19'], [16.009174311926607, '21'], [10.25, '08'], [7.796296296296297, '03'], [7.170212765957447, '04'], [13.233644859813085, '14'], [6.746478873239437, '22'], [11.051724137931034, '11'], [11.383333333333333, '01'], [16.796296296296298, '16'], [38.5948275862069, '15'], [9.022727272727273, '06'], [13.20183486238532, '18'], [5.5777777777777775, '09'], [13.440677966101696, '10'], [10.08695652173913, '05'], [14.741176470588234, '13'], [7.852941176470588, '07'], [9.41095890410959, '12'], [21.525, '20'], [8.127272727272727, '00'], [11.46, '17'], [7.985294117647059, '23'], [23.810344827586206, '02']]\n",
      "\n",
      "\n",
      "[[38.5948275862069, '15'], [23.810344827586206, '02'], [21.525, '20'], [16.796296296296298, '16'], [16.009174311926607, '21'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [13.20183486238532, '18'], [11.46, '17'], [11.383333333333333, '01'], [11.051724137931034, '11'], [10.8, '19'], [10.25, '08'], [10.08695652173913, '05'], [9.41095890410959, '12'], [9.022727272727273, '06'], [8.127272727272727, '00'], [7.985294117647059, '23'], [7.852941176470588, '07'], [7.796296296296297, '03'], [7.170212765957447, '04'], [6.746478873239437, '22'], [5.5777777777777775, '09']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print(sorted_swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00: 38.59 average comments per post \n",
      "02:00: 23.81 average comments per post \n",
      "20:00: 21.52 average comments per post \n",
      "16:00: 16.80 average comments per post \n",
      "21:00: 16.01 average comments per post \n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "for average, hour in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post \"\n",
    "        .format(dt.datetime.strptime(hour, \"%H\").strftime(\"%H:%M\"),average))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
